{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/amani/miniconda3/envs/sigmae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from  notebook_utils import run_inference, send_batch_to_device\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### analysis of the model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /mnt/dlabscratch1/amani/sigmae/notebooks\n",
      "Instantiating data module <src.data.datamodule.image_lightning_datamodule.ImagePLDataModule>\n",
      "Instantiating model <src.models.sigmae_lit_module_im_to_text.SigmaeLitModuleImageToText>\n"
     ]
    }
   ],
   "source": [
    "path = \"/dlabscratch1/amani/sigmae/logs/train/runs/2024-09-12_13-07-22/\"\n",
    "\n",
    "batch_size = 32\n",
    "model_path = path + \"checkpoints/last.ckpt\"\n",
    "configs_path = path + \".hydra/\"\n",
    "config_name = \"config.yaml\"\n",
    "with hydra.initialize_config_dir(config_dir=configs_path, version_base=\"1.2\"):\n",
    "    config = hydra.compose(config_name=config_name, \n",
    "                           overrides=[f\"data.batch_size={batch_size}\", \n",
    "                                    f\"ckpt_path={model_path}\"\n",
    "                                    ])\n",
    "\n",
    "model, datamodule = run_inference(config)\n",
    "datamodule.processor_z = model.processor_z\n",
    "datamodule.processor_x = None # for image text\n",
    "datamodule.setup('test', processor_z=model.processor_z)\n",
    "\n",
    "test_datamodule = datamodule.test_dataloader()\n",
    "batch = next(iter(test_datamodule))\n",
    "batch = send_batch_to_device(batch, model.device)\n",
    "output = model.forward(batch['x'], batch['z'], batch['data_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['zxz']['id_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### printing stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 42\n",
    "dataset='val'\n",
    "\n",
    "# print('supervised model 0.04:')\n",
    "# forward(model_sup_004, datamodule_sup_004, id, dataset=dataset)\n",
    "# print('curriculum model 0.04:')\n",
    "# forward(model_cur_004, datamodule_cur_004, id, dataset=dataset)\n",
    "\n",
    "################################################ single model ##########################################################\n",
    "print('id:{} dataset:{}'.format(id, dataset))\n",
    "forward(model, datamodule, id, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_neat_matrix(model.disc_x.dictionary.weight)\n",
    "# torch.linalg.vector_norm(model.disc_x.dictionary.weight, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.isnan().any())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = next(iter(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 20\n",
    "model = model\n",
    "datamodule = datamodule\n",
    "print(datamodule.data_train[id])\n",
    "pred_from_sample(model, datamodule, 'turn left after walk opposite right', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'turn left', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right after turn left', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right after turn left and walk opposite right after turn left', print_x_or_z='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model\n",
    "z_vocab = ['I_RUN', 'I_JUMP', 'I_WALK', 'I_LOOK', 'I_TURN_LEFT', 'I_TURN_RIGHT', ]\n",
    "x_vocab = ['left', 'thrice', 'after','and', 'right', 'turn', 'run', 'walk', 'look', 'jump', 'opposite', \n",
    "        'around', 'twice']\n",
    "\n",
    "pred_from_sample(model, 'I_JUMP', print_x_or_z='x')\n",
    "pred_from_sample(model, 'I_JUMP I_JUMP', print_x_or_z='x')\n",
    "pred_from_sample(model, 'I_JUMP I_JUMP I_JUMP', print_x_or_z='x')\n",
    "pred_from_sample(model, 'I_JUMP I_JUMP I_JUMP I_JUMP', print_x_or_z='x')\n",
    "\n",
    "\n",
    "pred_from_sample(model, 'jump and jump', print_x_or_z='z')\n",
    "pred_from_sample(model, 'jump twice', print_x_or_z='z')\n",
    "pred_from_sample(model, 'jump twice and jump', print_x_or_z='z')\n",
    "pred_from_sample(model, 'jump and jump and jump', print_x_or_z='z')\n",
    "pred_from_sample(model, 'jump and jump and jump and jump', print_x_or_z='z')\n",
    "pred_from_sample(model, 'jump around left', print_x_or_z='z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_sup_004\n",
    "sentence = 'walk twice and turn left twice'\n",
    "pred_from_sample(model, sentence, print_x_or_z='z')\n",
    "model = model_cur_004\n",
    "pred_from_sample(model, sentence, print_x_or_z='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ameliorated val datapoints from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_z_ids_cur, correct_x_ids_cur = correct_val_predictions(model_cur_004, datamodule_cur_004)\n",
    "correct_z_ids_sup, correct_x_ids_sup = correct_val_predictions(model_sup_004, datamodule_sup_004)\n",
    "intersection = list(set(correct_z_ids_cur).intersection(set(correct_x_ids_cur)))\n",
    "lost_z_ids_by_cur = list(set(correct_z_ids_sup).difference(set(correct_z_ids_cur)))\n",
    "found_z_ids_by_cur = list(set(correct_z_ids_cur).difference(set(correct_z_ids_sup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('curriculum accuracy: ', len(correct_z_ids_cur)/len(datamodule_cur_004.data_val))\n",
    "print('supervised accuracy: ', len(correct_z_ids_sup)/len(datamodule_sup_004.data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size of lost z ids by curr: ',len(lost_z_ids_by_cur))\n",
    "print('size of found z ids by curr: ',len(found_z_ids_by_cur))\n",
    "\n",
    "i = 20\n",
    "print('supervised model 0.04:')\n",
    "forward(model_sup_004, datamodule_sup_004, lost_z_ids_by_cur[i])\n",
    "print('curriculum model 0.04:')\n",
    "forward(model_cur_004, datamodule_cur_004, lost_z_ids_by_cur[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "print('supervised model 0.04:')\n",
    "forward(model_sup_004, datamodule_sup_004, found_z_ids_by_cur[i])\n",
    "print('curriculum model 0.04:')\n",
    "forward(model_cur_004, datamodule_cur_004, found_z_ids_by_cur[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_z_ids_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_z_ids_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why is the fully supervised model with perfect loss not working well on zxz and xzx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "path=\"'/dlabdata1/masani/blocks/logs/training/runs/scan/suponly-[0.99, 0.9]-gpt2_gpt2-vqvae/2023-11-15_13-48-10/checkpoints/last.ckpt'\"\n",
    "\n",
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    config_sup = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=scan\", \"datamodule.dataset_parameters.supervision_ratio=[0.99,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\"\n",
    "                                      ])\n",
    "\n",
    "model_sup , datamodule_sup = run_inference(config_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 20\n",
    "model = model_sup\n",
    "datamodule = datamodule_sup\n",
    "print(datamodule_sup.data_train[id])\n",
    "forward(model_sup, datamodule_sup, id, dataset='train')\n",
    "pred_from_sample(model, datamodule, 'turn left after walk opposite right', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'turn left', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right after turn left', print_x_or_z='z')\n",
    "pred_from_sample(model, datamodule, 'walk opposite right after turn left and walk opposite right after turn left', print_x_or_z='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.disc_x.dictionary.weight)\n",
    "dictionary_cosine_sim(model, alphabet='x', bins=100)\n",
    "dictionary_inner_prod_sim(model, alphabet='x', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_z_ids, correct_x_ids = correct_val_predictions(model_sup, datamodule_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## model weights analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of functions\n",
    "def dictionary_cosine_sim(model, alphabet='x', bins=100):\n",
    "    if alphabet == 'x':\n",
    "        kernel = model.disc_x.state_dict()['dictionary.weight'].cpu().numpy()\n",
    "    elif alphabet == 'z':\n",
    "        kernel = model.disc_z.state_dict()['dictionary.weight'].cpu().numpy()\n",
    "    # cosine similarity\n",
    "    inner_prods = kernel.dot(kernel.T)\n",
    "    lengths = np.linalg.norm(kernel, axis=1)\n",
    "    length_matrix = np.outer(lengths, lengths)\n",
    "    kernel = np.round(inner_prods / length_matrix, decimals=2)\n",
    "    u = plt.hist(kernel.flatten(), bins=bins)\n",
    "    plt.show()\n",
    "    return kernel, u\n",
    "\n",
    "\n",
    "def dictionary_inner_prod_sim(model, alphabet='x', bins=100):\n",
    "    if alphabet == 'x':\n",
    "        kernel = model.disc_x.state_dict()['dictionary.weight'].cpu().numpy()\n",
    "    elif alphabet == 'z':\n",
    "        kernel = model.disc_z.state_dict()['dictionary.weight'].cpu().numpy()\n",
    "    inner_prods = kernel.dot(kernel.T)\n",
    "    kernel = np.round(inner_prods, decimals=2)\n",
    "    u = plt.hist(kernel.flatten(), bins=bins)\n",
    "    plt.show()\n",
    "    return kernel, u\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel, u = dictionary_inner_prod_sim(model, alphabet='z', bins=100)\n",
    "print_neat_matrix(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "path=\"'/dlabdata1/masani/blocks/logs/training/runs/scan/suponly-[0.04, 0.9]-gpt2_gpt2-vqvae/2023-10-15_14-51-47/checkpoints/last.ckpt'\"\n",
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    config_sup_004 = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=scan\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\"\n",
    "                                      ])\n",
    "\n",
    "model_sup_004 , datamodule_sup_004 = run_inference(config_sup_004)\n",
    "\n",
    "batch_size = 10\n",
    "path=\"'/dlabdata1/masani/blocks/logs/training/runs/scan/curriculum-[0.04, 0.9]-gpt2_gpt2-vqvae/2023-10-17_14-13-22/checkpoints/last.ckpt'\"\n",
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    config_cur_004 = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=scan\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\"\n",
    "                                      ])\n",
    "\n",
    "model_cur_004, datamodule_cur_004 = run_inference(config_cur_004)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annot = False\n",
    "for alph in ['x', 'z']:\n",
    "    if alph == 'x':\n",
    "        bin = 100\n",
    "        tokenizer=model.collator.tokenizer_x\n",
    "    elif alph == 'z':\n",
    "        bin = 20\n",
    "        tokenizer=model.collator.tokenizer_z\n",
    "    print(alph)\n",
    "    for type in ['sup', 'cur']:\n",
    "        print(type)\n",
    "        if type == 'sup':\n",
    "            model = model_sup_004\n",
    "        elif type == 'cur':\n",
    "            model = model_cur_004\n",
    "        cosine_kernel, cosine_u = dictionary_cosine_sim(model, alphabet=alph, bins=bin)\n",
    "\n",
    "        sorted_vocab = sorted(tokenizer.get_vocab().items(), key=lambda x: x[1])\n",
    "        sorted_vocab = [x[0] for x in sorted_vocab]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(alph+' '+type+' cosine similarity')\n",
    "        sns.heatmap(cosine_kernel, cmap=\"coolwarm\", annot=annot, xticklabels=sorted_vocab, yticklabels=sorted_vocab)\n",
    "        plt.show()\n",
    "\n",
    "        inner_prod_kernel, inner_prod_u = dictionary_inner_prod_sim(model, alphabet=alph, bins=bin)\n",
    "        plt.figure()\n",
    "        plt.title(alph+' '+type+' inner product similarity')\n",
    "        sns.heatmap(inner_prod_kernel, cmap=\"coolwarm\", annot=annot, xticklabels=sorted_vocab, yticklabels=sorted_vocab)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# cos_sup_004, u_sup_004 = dictionary_cosine_sim(model_sup_004, bins=bin)\n",
    "# cos_cur_004, u_cur_004 = dictionary_cosine_sim(model_cur_004, bins=bin)\n",
    "# sns.heatmap(cos_sup_004, cmap=\"coolwarm\", annot=True)\n",
    "# plt.show()\n",
    "# sns.heatmap(cos_cur_004, cmap=\"coolwarm\", annot=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading other datamodules and sampling outputs for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from src import utils\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from src.utils.metrics import pad_label_label\n",
    "# from src.utils import general_helpers\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, LightningDataModule, Trainer\n",
    "from pytorch_lightning.loggers.logger import Logger\n",
    "\n",
    "import src.utils.general as utils\n",
    "# Load config\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log = utils.get_pylogger(__name__)\n",
    "\n",
    "configs_path = \"../configs\"\n",
    "config_name = \"inference_root.yaml\"\n",
    "work_dir='/dlabdata1/masani/blocks/'\n",
    "batch_size = 32\n",
    "path=\"'/dlabdata1/masani/blocks/logs/training/runs/scan/suponly-[0.99, 0.9]-gpt2_gpt2-vqvae/2023-11-17_15-54-41/checkpoints/last.ckpt'\"\n",
    "\n",
    "def load_datamodule(config: DictConfig):\n",
    "    # assert config.output_dir is not None, \"Path to the directory in which the predictions will be written must be given\"\n",
    "    # config.output_dir = general_helpers.get_absolute_path(config.output_dir)\n",
    "    # log.info(f\"Output directory: {config.output_dir}\")\n",
    "\n",
    "    # Set seed for random number generators in PyTorch, Numpy and Python (random)\n",
    "    if config.get(\"seed\"):\n",
    "        pl.seed_everything(config.seed, workers=True)\n",
    "    \n",
    "    # print current working directory\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    print(f\"Instantiating data module <{config.datamodule._target_}>\")\n",
    "    datamodule: LightningDataModule = hydra.utils.instantiate(config.datamodule, _recursive_=False)\n",
    "\n",
    "    return datamodule\n",
    "\n",
    "def print_sample(datamodule, num_sample):\n",
    "    ids = np.random.randint(0, len(datamodule.data_val), num_sample)\n",
    "    for id in ids:\n",
    "        print('id: ', id)\n",
    "        print('x: ', datamodule.data_val[int(id)]['x'])\n",
    "        print('z: ', datamodule.data_val[int(id)]['z'])\n",
    "        print('_____________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    cnfig = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=cfq\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\",\n",
    "                                      \"work_dir='/dlabdata1/masani/blocks/'\"\n",
    "                                      ])\n",
    "datamodule = load_datamodule(cnfig)\n",
    "print_sample(datamodule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    cnfig = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=cogs\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\",\n",
    "                                      \"work_dir='/dlabdata1/masani/blocks/'\"\n",
    "                                      ])\n",
    "datamodule = load_datamodule(cnfig)\n",
    "print_sample(datamodule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    cnfig = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=pcfg_set\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\",\n",
    "                                      \"work_dir='/dlabdata1/masani/blocks/'\"\n",
    "                                      ])\n",
    "datamodule = load_datamodule(cnfig)\n",
    "print_sample(datamodule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    cnfig = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=sfst\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\"\n",
    "                                      ])\n",
    "datamodule = load_datamodule(cnfig)\n",
    "print_sample(datamodule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=configs_path, version_base=\"1.2\"):\n",
    "    cnfig = hydra.compose(config_name=config_name, \n",
    "                           overrides=[\"+experiment/inference=inference\", \n",
    "                                      \"datamodule=scan\", \"datamodule.dataset_parameters.supervision_ratio=[0.04,0.9]\",\n",
    "                                      \"trainer.devices=[1]\", \n",
    "                                      \"training_type=suponly\", \n",
    "                                      f\"datamodule.dataset_parameters.batch_size={batch_size}\", \n",
    "                                      \"sequence_to_sequence_model_key=gpt2_gpt2\", \n",
    "                                      \"discretizer_key=vqvae\",\n",
    "                                      f\"model.checkpoint_path={path}\"\n",
    "                                      ])\n",
    "datamodule = load_datamodule(cnfig)\n",
    "print_sample(datamodule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
