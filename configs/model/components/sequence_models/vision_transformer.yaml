defaults:
  - default

_target_: symbolic_bottleneck.auto_reg_wrapper.ImageInputAutoRegWrapper

model:
  _target_: transformers.VisionEncoderDecoderModel
  config:
    _target_: transformers.VisionEncoderDecoderConfig.from_encoder_decoder_configs
    encoder_config:
      _target_: transformers.ViTConfig
      attention_probs_dropout_prob: 0.0
      encoder_stride: ${model.model_params.z_patch_size}
      hidden_act: "gelu"
      hidden_dropout_prob: 0.0
      hidden_size: ${model.model_params.d_model}
      image_size: ${model.model_params.image_size}
      initializer_range: 0.02
      intermediate_size: ${mult_int:${model.model_params.d_model},4} # In vit-gpt2 it's 4 times the hidden size so I defaulted to this
      layer_norm_eps: 1e-12
      model_type: "vit"
      num_attention_heads: 8
      num_channels: ${model.model_params.num_channels}
      num_hidden_layers: 8
      patch_size: ${model.model_params.z_patch_size}
      qkv_bias: true

    decoder_config:
      _target_: transformers.GPT2Config
      activation_function": "gelu_new"
      add_cross_attention": true
      architectures": ["GPT2LMHeadModel"]
      attn_pdrop: 0.1
      embd_pdrop: 0.1
      initializer_range: 0.02
      is_decoder: true
      layer_norm_epsilon: 1e-05
      model_type: "gpt2"
      n_ctx: ${add_int:${model.model_params.max_x_length},${model.model_params.max_z_length}}
      n_embd: ${model.model_params.d_model}
      n_head: 8
      n_inner: null
      n_layer: 8
      n_positions: ${add_int:${model.model_params.max_x_length},${model.model_params.max_z_length}}
      reorder_and_upcast_attn: false
      resid_pdrop: 0.1
      scale_attn_by_inverse_layer_idx: false
      scale_attn_weights: true
      summary_activation: null
      summary_first_dropout: 0.1
      summary_proj_to_labels: true
      summary_type: "cls_index"
      summary_use_proj: true
      vocab_size: ${model.model_params.x_vocab_size}

processor:
  _target_: transformers.ViTImageProcessor
  do_normalize: true
  do_rescale: true
  do_resize: true
  image_mean: ${model.model_params.processor.image_mean} #in function of of image and number of channels
  image_processor_type: “ViTImageProcessor”
  image_std: ${model.model_params.processor.image_std}
  resample: 2
  rescale_factor: 0.00392
  size: ${model.model_params.processor.image_size}

model_unwrapper: 
  _target_: symbolic_bottleneck.modules.model_unwrapper.transformer_enc_dec_unwrapper.EncoderDecoderUnwrapper

config:
  output_prepending_ids: null
  
  max_lengths:
    input: 1 # is  this right ?
    output: 45
  device: cpu
  use_past_key_values: False
  use_last_step_states: False
  soft_average:
    p_eos_backward: True
    p_eos_forward: False 
    word_embeds_with_scores_forward: True