# !!!! WE DON'T USE THIS FILE YET !!!!
_target_: symbolic_bottleneck.auto_reg_wrapper.AudioInputAutoRegWrapper
model:
  _target_: transformers.SpeechEncoderDecoderModel
  config:
    #Inspired from: "facebook/wav2vec2-xls-r-300m-en-to-15"
    _target_: transformers.SpeechEncoderDecoderConfig.from_encoder_decoder_configs
    encoder_config:
      _target_: transformers.Wav2Vec2Config
      activation_dropout: 0.0
      add_adapter: true
      codevector_dim: 768 ## Not sure what this is or if we need it
      conv_bias: true
      do_stable_layer_norm: true
      feat_extract_dropout: 0.0
      feat_extract_norm: "layer"
      feat_proj_dropout: 0.1
      final_dropout: 0.1
      gradient_checkpointing: false
      hidden_size: ${model.model_params.d_model}
      initializer_range: 0.02
      intermediate_size: ${mult_int:${model.model_params.d_model},4} # In  "facebook/wav2vec2-xls-r-300m-en-to-15" it's 4 times the hidden size so I defaulted to this
      layer_norm_eps: 1e-05
      mask_time_prob: 0.075
      num_adapter_layers: 3
      num_attention_heads: 8
      num_feat_extract_layers: 7
      num_hidden_layers: 8
      output_hidden_size: ${model.model_params.d_model}
      proj_codevector_dim: 768 ## Not sure what this is or if we need it
      vocab_size: ${model.model_params.x_vocab_size} # I think this is right but double check

    decoder_config:
      _target_: transformers.GPT2Config
      activation_function": "gelu_new"
      add_cross_attention": true
      architectures": ["GPT2LMHeadModel"]
      attn_pdrop: 0.1
      embd_pdrop: 0.1
      initializer_range: 0.02
      is_decoder: true
      layer_norm_epsilon: 1e-05
      model_type: "gpt2"
      n_ctx: ${add_int:${model.model_params.max_x_length},${model.model_params.max_z_length}}
      n_embd: ${model.model_params.d_model}
      n_head: 8
      n_inner: null
      n_layer: 8
      n_positions: ${add_int:${model.model_params.max_x_length},${model.model_params.max_z_length}}
      reorder_and_upcast_attn: false
      resid_pdrop: 0.1
      scale_attn_by_inverse_layer_idx: false
      scale_attn_weights: true
      summary_activation: null
      summary_first_dropout: 0.1
      summary_proj_to_labels: true
      summary_type: "cls_index"
      summary_use_proj: true
      vocab_size: ${model.model_params.x_vocab_size}

processor:
  # _target_: transformers.Wav2Vec2Processor
  # feature_extractor:
  _target_: transformers.Wav2Vec2FeatureExtractor
  do_normalize: true
  feature_size: 1
  padding_side: right
  padding_value: 0
  return_attention_mask: True
  sampling_rate: 16000
  
  # tokenizer: null
  

model_unwrapper: 
  _target_: symbolic_bottleneck.modules.model_unwrapper.transformer_enc_dec_unwrapper.EncoderDecoderUnwrapper

config:
  output_prepending_ids: null
  max_lengths:
    input: ???
    output: 45
  device: cpu
  use_past_key_values: False
  use_last_step_states: False
  soft_average:
    p_eos_backward: True
    p_eos_forward: False 
    word_embeds_with_scores_forward: True