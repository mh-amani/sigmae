_target_: ???
# if you dont provide dimensions, then it will take the dimensions from your models' encoder and decoder embeddings shapes.
# and will use themseleves for the unembedding.
config:
  dimensions: null # None for using the models' encoder and decoder embeddings shapes. otherwise provide a dict with the following keys: vocab_size, encoder_embedding_dim, decoder_embedding_dim, unembedding_dim
  quantize_vector: True
  temperature: 1.0
  encoder_embedding_trainable: True
  decoder_embedding_trainable: True
  linear_head_trainable: True
  encoder_embedding: None
  decoder_embedding: None
  linear_head: None